# ==========================================
# Training Hyperparameters
# ==========================================
train:
  epochs: 10000
  batch_size: 64
  eval_batch_size: 1024
  lr: 0.0002 # 0.01 would be a good start for SGD
# ==========================================
# Diffusion Model Architecture & Schedule
# ==========================================
diffusion:
  diffusion_embedding_dim: 128
  num_steps: 50
  sum_scale: 0.01
# ==========================================
# Model Feature Embeddings
# ==========================================
model:
  net: "Dense"
  featureemb: 64
  channels: 64
  nheads: 4
  layers: 3
  dropout: 0.2
# ==========================================
# Testing / Imputation
# ==========================================
else:
  samp: "BLS"
  task: "Res-N"
  m: 5
  mi_approx: "None" # switching between "SWAG", "CRC, "dropout", "bootstrap", "None"
                       # "SWAG" is very unstable due to SGD optimizer
                       # "dropout" may lose some uncertainty
                       # "bootstrap" is slow
